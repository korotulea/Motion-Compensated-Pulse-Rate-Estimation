{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Your Algorithm\n",
    "\n",
    "## Instructions\n",
    "1. From the **Pulse Rate Algorithm** Notebook you can do one of the following:\n",
    "   - Copy over all the **Code** section to the following Code block.\n",
    "   - Download as a Python (`.py`) and copy the code to the following Code block.\n",
    "2. In the bottom right, click the <span style=\"color:blue\">Test Run</span> button. \n",
    "\n",
    "### Didn't Pass\n",
    "If your code didn't pass the test, go back to the previous Concept or to your local setup and continue iterating on your algorithm and try to bring your training error down before testing again.\n",
    "\n",
    "### Pass\n",
    "If your code passes the test, complete the following! You **must** include a screenshot of your code and the Test being **Passed**. Here is what the starter filler code looks like when the test is run and should be similar. A passed test will include in the notebook a green outline plus a box with **Test passed:** and in the Results bar at the bottom the progress bar will be at 100% plus a checkmark with **All cells passed**.\n",
    "![Example](example.png)\n",
    "\n",
    "1. Take a screenshot of your code passing the test, make sure it is in the format `.png`. If not a `.png` image, you will have to edit the Markdown render the image after Step 3. Here is an example of what the `passed.png` would look like \n",
    "2. Upload the screenshot to the same folder or directory as this jupyter notebook.\n",
    "3. Rename the screenshot to `passed.png` and it should show up below.\n",
    "![Passed](passed.png)\n",
    "4. Download this jupyter notebook as a `.pdf` file. \n",
    "5. Continue to Part 2 of the Project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "edited": true,
    "gradable": true,
    "grader_id": "nrtnppao4pm",
    "udacity_user_query": ""
   },
   "outputs": [],
   "source": [
    "# replace the code below with your pulse rate algorithm.\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "import scipy.stats\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def LoadTroikaDataset():\n",
    "    \"\"\"\n",
    "    Retrieve the .mat filenames for the troika dataset.\n",
    "\n",
    "    Review the README in ./datasets/troika/ to understand the organization of the .mat files.\n",
    "\n",
    "    Returns:\n",
    "        data_fls: Names of the .mat files that contain signal data\n",
    "        ref_fls: Names of the .mat files that contain reference data\n",
    "        <data_fls> and <ref_fls> are ordered correspondingly, so that ref_fls[5] is the \n",
    "            reference data for data_fls[5], etc...\n",
    "    \"\"\"\n",
    "    data_dir = \"./datasets/troika/training_data\"\n",
    "    data_fls = sorted(glob.glob(data_dir + \"/DATA_*.mat\"))\n",
    "    ref_fls = sorted(glob.glob(data_dir + \"/REF_*.mat\"))\n",
    "    return data_fls, ref_fls\n",
    "\n",
    "def LoadTroikaDataFile(data_fl):\n",
    "    \"\"\"\n",
    "    Loads and extracts signals from a troika data file.\n",
    "\n",
    "    Usage:\n",
    "        data_fls, ref_fls = LoadTroikaDataset()\n",
    "        ppg, accx, accy, accz = LoadTroikaDataFile(data_fls[0])\n",
    "\n",
    "    Args:\n",
    "        data_fl: (str) filepath to a troika .mat file.\n",
    "\n",
    "    Returns:\n",
    "        numpy arrays for ppg, accx, accy, accz signals.\n",
    "    \"\"\"\n",
    "    data = sp.io.loadmat(data_fl)['sig']\n",
    "    return data[2:]\n",
    "\n",
    "def AggregateErrorMetric(pr_errors, confidence_est):\n",
    "    \"\"\"\n",
    "    Computes an aggregate error metric based on confidence estimates.\n",
    "\n",
    "    Computes the MAE at 90% availability. \n",
    "\n",
    "    Args:\n",
    "        pr_errors: a numpy array of errors between pulse rate estimates and corresponding \n",
    "            reference heart rates.\n",
    "        confidence_est: a numpy array of confidence estimates for each pulse rate\n",
    "            error.\n",
    "\n",
    "    Returns:\n",
    "        the MAE at 90% availability\n",
    "    \"\"\"\n",
    "    # Higher confidence means a better estimate. The best 90% of the estimates\n",
    "    #    are above the 10th percentile confidence.\n",
    "    percentile90_confidence = np.percentile(confidence_est, 10)\n",
    "\n",
    "    # Find the errors of the best pulse rate estimates\n",
    "    best_estimates = pr_errors[confidence_est >= percentile90_confidence]\n",
    "\n",
    "    # Return the mean absolute error\n",
    "    return np.mean(np.abs(best_estimates))\n",
    "\n",
    "def Evaluate():\n",
    "    \"\"\"\n",
    "    Top-level function evaluation function.\n",
    "\n",
    "    Runs the pulse rate algorithm on the Troika dataset and returns an aggregate error metric.\n",
    "\n",
    "    Returns:\n",
    "        Pulse rate error on the Troika dataset. See AggregateErrorMetric.\n",
    "    \"\"\"\n",
    "    # Retrieve dataset files\n",
    "    data_fls, ref_fls = LoadTroikaDataset()\n",
    "    errs, confs = [], []\n",
    "    for data_fl, ref_fl in zip(data_fls, ref_fls):\n",
    "        # Run the pulse rate algorithm on each trial in the dataset\n",
    "        errors, confidence = RunPulseRateAlgorithm(data_fl, ref_fl)\n",
    "        errs.append(errors)\n",
    "        confs.append(confidence)\n",
    "        # Compute aggregate error metric\n",
    "    errs = np.hstack(errs)\n",
    "    confs = np.hstack(confs)\n",
    "    return AggregateErrorMetric(errs, confs)\n",
    "\n",
    "def BandpassFilter(signal, lowcut=40./60, highcut=240./60, fs=125):\n",
    "    \"\"\"\n",
    "    Loads the signal and passes it through a Butterworth bandpass filter.\n",
    "    Args:\n",
    "        signal: array_like, signal data to be filtered\n",
    "        lowcat: float, low cut frequency in Hz\n",
    "        highcut: float, high cut frequency in Hz\n",
    "        fs: float, the sampling frequency of the digital system in Hz\n",
    "    Returns:\n",
    "        array_like, Band Pass filtered Signal\n",
    "    \"\"\"\n",
    "    # Initiate bandpass filter\n",
    "    b, a = sp.signal.butter(3, (lowcut, highcut), btype='bandpass', fs=fs)\n",
    "    # Apply Butterworth bandpass filter and return filtered signal\n",
    "    return sp.signal.filtfilt(b, a, signal)\n",
    "\n",
    "def FourierTransform(signal, fs=125, zerofill=2):\n",
    "    \"\"\"\n",
    "    Loads the signal and do a Discrete Fourier Transform on the signal\n",
    "    Args:\n",
    "        signal: array_like, signal data to apply Discrete Fourier Transform \n",
    "        fs: float, the sampling frequency of the digital system in Hz\n",
    "        zerofill: int, zero fill spectrum\n",
    "    Returns:\n",
    "        array_like, frequency and magnitude of the signal\n",
    "    \"\"\"\n",
    "    # Compute discrete Fourier Transform sample frequencies\n",
    "    fftlen = len(signal) * zerofill # for zero padding\n",
    "    freqs = np.fft.rfftfreq(fftlen, 1/fs)\n",
    "    # Compute the one-dimensional discrete Fourier Transform for real input\n",
    "    fft = np.abs(np.fft.rfft(signal, fftlen))\n",
    "    return freqs, fft\n",
    "\n",
    "def spectrogram_show(signal, fs, signal_name, ylimits=(0.5, 5.5), estimates=None):\n",
    "    '''\n",
    "    Plot spectrogram with or without estimates\n",
    "    Args:\n",
    "        signal: array_like, signal data to apply Discrete Fourier Transform \n",
    "        fs: float, the sampling frequency of the digital system in Hz\n",
    "        signal_name: string, name of the signal to show on the image\n",
    "        ylimits: tuple, (0.5, 5.5) is default\n",
    "        estimates: None or array, the estimated frequencies\n",
    "    Returns:\n",
    "        Plot spectrogram   \n",
    "    '''\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    spec, freqs, t, _ = plt.specgram(signal, NFFT=fs*4, Fs=fs, noverlap=0);\n",
    "    plt.xlabel('Time (sec)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.ylim(ylimits)\n",
    "    if not (estimates is None):\n",
    "        plt.hlines(estimates, 0, len(signal)/fs, 'k')\n",
    "        plt.title(f'{signal_name} Signal Spectrogram with estimates')\n",
    "    else:\n",
    "        plt.title(f'{signal_name} Signal Spectrogram')\n",
    "    plt.show()\n",
    "\n",
    "def signal_fft_show(signal, fs, xlimits=(0, 10), ylimits=None, peaks=None):\n",
    "    '''\n",
    "    Plot signal and FFT with or without estimates\n",
    "    Args:\n",
    "        signal: array_like, signal data to apply Discrete Fourier Transform \n",
    "        fs: float, the sampling frequency of the digital system in Hz\n",
    "        xlimits: tuple, (0, 10) is default\n",
    "        ylimits: tuple, None is default\n",
    "        peaks: None or array, the estimated frequencies\n",
    "    Returns:\n",
    "        Plot signal and it's FFT   \n",
    "    '''\n",
    "    freqs, fft = FourierTransform(signal, fs=fs)\n",
    "    # smooth FFT with Savitzkyâ€“Golay filter\n",
    "    fft = scipy.signal.savgol_filter(fft, 5, 2)\n",
    "    ts = np.arange(0, len(signal)/fs, 1/fs)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(ts, signal)\n",
    "    plt.title('Time-Domain')\n",
    "    plt.xlabel('Time (sec)')\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(freqs, fft)\n",
    "    if not (peaks is None):\n",
    "        plt.plot(freqs[peaks], fft[peaks], 'r.', ms=10)\n",
    "    plt.title('Frequency-Domain')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.tight_layout()\n",
    "    plt.xlim(xlimits)\n",
    "    if ylimits:\n",
    "        plt.ylim(ylimits)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_signal_fft_spectrogram_estimates(signal, fs, signal_name, threshold, distance, freqs_limits=(0.5, 5.5)):\n",
    "    '''\n",
    "    Plot signal, FFT, and spectrogram with simple estimates\n",
    "    Args:\n",
    "        signal: array_like, signal data to apply Discrete Fourier Transform \n",
    "        fs: int, the sampling frequency of the digital system in Hz\n",
    "        signal_name: string, name of the signal to show on the image\n",
    "        threshold: float, the Y cut base on max Y value\n",
    "        distance: integer, min distance between peaks\n",
    "        freqs_limits: tuple, (0.5, 5.5) is default\n",
    "    Returns:\n",
    "        Plot signal, it's FFT, spectrogram with simple estimates\n",
    "        print out peak estimates and confidence ratio\n",
    "    '''\n",
    "    freqs, fft = FourierTransform(signal, fs=fs)\n",
    "    # smooth FFT with Savitzkyâ€“Golay filter\n",
    "    fft = scipy.signal.savgol_filter(fft, 3, 2)\n",
    "    pks = sp.signal.find_peaks(fft, height=np.max(fft)*threshold, distance=distance)[0]\n",
    "    estimates = freqs[pks]\n",
    "    signal_fft_show(signal, fs, xlimits=freqs_limits, peaks=pks)\n",
    "    spectrogram_show(signal, fs, signal_name, ylimits=freqs_limits, estimates=estimates)\n",
    "    print('Peaks esstimates Hz:', estimates)\n",
    "    print('Peaks esstimates Per/Min:', estimates*60)\n",
    "    confidence = []\n",
    "    for indx in range(len(pks)):\n",
    "        pk_l = freqs[int(pks[indx] - 10)]\n",
    "        pk_m = freqs[int(pks[indx] + 10)]\n",
    "        fft_pk = fft[(freqs >= pk_l) & (freqs <= pk_m)]\n",
    "        freqs_pk = freqs[(freqs >= pk_l) & (freqs <= pk_m)]\n",
    "        plt.plot(freqs_pk, fft_pk)\n",
    "        plt.show()\n",
    "        pk_confidence = np.sum(fft[(freqs >= pk_l) & (freqs <= pk_m)] / np.sum(fft))\n",
    "        confidence.append(pk_confidence) \n",
    "        print('Peak:', freqs[pks[indx]])\n",
    "        print('Confidence (ratio area under peak / fft area): ', pk_confidence)\n",
    "                               \n",
    "    return estimates, pks, confidence \n",
    " \n",
    "def FindPeaks(signal, fs, threshold, distance, sg_filter=True):\n",
    "    '''\n",
    "    Find peaks in the spectrum and calculate confidence of the peaks defined as a ratio \n",
    "    of sum of the frequency spectrum near the pulse rate estimate and the sum of the entire spectrum.\n",
    "    Args:\n",
    "        signal: array_like, signal data to apply Discrete Fourier Transform \n",
    "        fs: int, the sampling frequency of the digital system in Hz\n",
    "        threshold: float, the Y cut base on max Y value\n",
    "        distance: integer, min distance between peaks\n",
    "        sg_filte: True or False, applying Savitzkyâ€“Golay filter to smooth spectrum\n",
    "    Return:\n",
    "        estimates: list, peaks estimates in Hz \n",
    "        pks: list, peaks index in FFT spectrum\n",
    "        confidence: list, confidence ratio\n",
    "        freqs: array_like, frequencies \n",
    "        fft: array_like, fft \n",
    "    '''\n",
    "    # Fourier transform\n",
    "    freqs, fft = FourierTransform(signal, fs=fs, zerofill=2)\n",
    "    \n",
    "    # smooth FFT with Savitzkyâ€“Golay filter if set True\n",
    "    if sg_filter:\n",
    "        fft = scipy.signal.savgol_filter(fft, 5, 3)\n",
    "    \n",
    "    # get peaks\n",
    "    pks = sp.signal.find_peaks(fft, height=np.max(fft)*threshold, distance=distance)[0]\n",
    "    \n",
    "    # compute peaks\n",
    "    estimates = freqs[pks]\n",
    "    \n",
    "    # compute estimates\n",
    "    confidence = []\n",
    "    for indx in range(len(pks)):\n",
    "        pk_l = freqs[int(pks[indx] - 10)]\n",
    "        pk_m = freqs[int(pks[indx] + 10)]\n",
    "        fft_pk = fft[(freqs >= pk_l) & (freqs <= pk_m)]\n",
    "        freqs_pk = freqs[(freqs >= pk_l) & (freqs <= pk_m)]\n",
    "        pk_confidence = np.sum(fft[(freqs >= pk_l) & (freqs <= pk_m)] / np.sum(fft))\n",
    "        confidence.append(pk_confidence) \n",
    "                               \n",
    "    return estimates, pks, confidence, freqs, fft    \n",
    "    \n",
    "def Estimates(ppg_bp, acc_bp, wind_length, wind_shift, fs):\n",
    "    '''\n",
    "    Estimate heart rate in BMP\n",
    "    Args:\n",
    "        ppg_bp: array_like, bandpassed signal data from photoplethysmography sensor \n",
    "        acc_bp: array_like, bandpassed magnitude signal data from accelerator sensor \n",
    "        wind_length: int, time frame in seconds to collect signal for BMP estimation\n",
    "        wind_shift: int, time frame in seconds to output the BMP estimate\n",
    "        fs: int, the sampling frequency of the digital system in Hz\n",
    "    Return:\n",
    "    Hear rate estimate in BMP and confidence\n",
    "    '''\n",
    "    estimate_bmp, confidence = [], []\n",
    "    \n",
    "    for indx in range(0, len(ppg_bp) - wind_length*fs, wind_shift*fs):\n",
    "        ppg_wind = ppg_bp[indx:indx+wind_length*fs]\n",
    "        acc_wind = acc_bp[indx:indx+wind_length*fs]\n",
    "        \n",
    "        # get potential estimates\n",
    "        estimates_ppg, pks_ppg, confidence_ppg, freqs_ppg, fft_ppg = \\\n",
    "                                        FindPeaks(ppg_wind, fs, 0.3, 1, sg_filter=True)\n",
    "        estimates_acc, pks_acc, confidence_acc, freqs_acc, fft_acc = \\\n",
    "                                        FindPeaks(acc_wind, fs, 0.3, 20, sg_filter=True)\n",
    "        \n",
    "        # create exclution indexes base on acc peaks\n",
    "        exclude_acc = [list(range(tmp - 2, tmp + 3)) for tmp in pks_acc]\n",
    "        exclude_acc_np = np.array(exclude_acc).flatten()\n",
    "        \n",
    "        # check that there is a ppg peak\n",
    "        if len(estimates_ppg) == 0:\n",
    "            estimate_bmp_tmp = freqs_ppg[np.argsort(fft_ppg, axis=0)[::-1][0]] * 60\n",
    "            confidence_tmp = 0.0\n",
    "        elif len(estimates_ppg) == 1:\n",
    "            estimate_bmp_tmp = freqs_ppg[pks_ppg[0]] * 60\n",
    "            confidence_tmp = confidence_ppg[0]           \n",
    "        else:\n",
    "            # sort peaks and check if acc peak is not overlapping with the ppg peaks \n",
    "            # the criteria is, the acc peak shouldn be within FWHM of the acc peaks\n",
    "            estimate_ppg_indx = []\n",
    "            pks_ppg_sorted = np.argsort(fft_ppg[pks_ppg], axis=0)[::-1]\n",
    "            #pks_acc_sorted = np.argsort(fft_acc[pks_acc], axis=0)[::-1]            \n",
    "            for indx_pks in pks_ppg_sorted:\n",
    "                #for fft_max_acc in pks_acc_sorted:\n",
    "                if (pks_ppg[indx_pks] not in exclude_acc_np): #& (indx_pks not in estimate_ppg_indx):\n",
    "                    estimate_ppg_indx.append(indx_pks)\n",
    "            if len(estimate_ppg_indx) == 0:\n",
    "                estimate_ppg_indx = pks_ppg_sorted\n",
    "            estimate_bmp_tmp = freqs_ppg[pks_ppg[estimate_ppg_indx[0]]] * 60\n",
    "            confidence_tmp = confidence_ppg[estimate_ppg_indx[0]]      \n",
    "        \n",
    "        # in case of BMP jumps more than 20 BMP from previous 2 sec, \n",
    "        # the BMP and confidence will be computed as anaverage of the last 3 calculations \n",
    "        if len(estimate_bmp) > 1:\n",
    "            if abs(estimate_bmp[-1] - estimate_bmp_tmp) >= 20:\n",
    "                estimate_bmp_tmp = (estimate_bmp_tmp + estimate_bmp[-1] + estimate_bmp[-2])/3\n",
    "                confidence_tmp = (confidence_tmp + confidence[-1] + confidence[-2])/3\n",
    "        # add estimated BMP and Confidence to the list\n",
    "        estimate_bmp.append(estimate_bmp_tmp)\n",
    "        confidence.append(confidence_tmp)       \n",
    "        \n",
    "    return np.array(estimate_bmp), np.array(confidence)\n",
    "\n",
    "def RunPulseRateAlgorithm(data_fl, ref_fl):\n",
    "    # Set sampling rate and window lenght and shift \n",
    "    fs = 125\n",
    "    wind_length = 8\n",
    "    wind_shift = 2\n",
    "    \n",
    "    # Load data using LoadTroikaDataFile\n",
    "    ppg, accx, accy, accz = LoadTroikaDataFile(data_fl)\n",
    "    \n",
    "    # Load ground truth \n",
    "    gt = sp.io.loadmat(ref_fl)['BPM0'].reshape(-1)\n",
    "    \n",
    "    # Bandpass signals\n",
    "    ppg_bp = BandpassFilter(ppg)\n",
    "    accx_bp = BandpassFilter(accx)\n",
    "    accy_bp = BandpassFilter(accy)\n",
    "    accz_bp = BandpassFilter(accz)\n",
    "    \n",
    "    # Combine x, y, z accelerator signals (magnitude)\n",
    "    acc_bp = BandpassFilter(np.sqrt(np.square(accx_bp) + np.square(accx_bp) + np.square(accx_bp)))\n",
    "    \n",
    "    # Compute pulse rate estimates and estimation confidence.\n",
    "    estimate_bmp, confidence = Estimates(ppg_bp, acc_bp, wind_length, wind_shift, fs)\n",
    "\n",
    "    # Return per-estimate mean absolute error and confidence as a 2-tuple of numpy arrays.\n",
    "    len_data = min(len(estimate_bmp), len(gt))\n",
    "    errors = np.abs(estimate_bmp[:len_data] - gt[:len_data])\n",
    "\n",
    "    return errors[:len_data], confidence[:len_data]"
   ]
  }
 ],
 "metadata": {
  "grader_mode": "",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "showGradeBtn": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
